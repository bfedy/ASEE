[["correlation-and-linear-regression.html", "Chapter 7 Correlation and Linear Regression 7.1 Correlation 7.2 Regression 7.3 Model Validation", " Chapter 7 Correlation and Linear Regression 7.1 Correlation 7.1.1 Correlation coefficient We addressed correlation with some code and examples provided in the Data Exploration chapter. This section will provide a few more details on correlation estimation and how to explore correlations with non-parametric data. Correlation is the most basic means of measuring the association between two variables. Pearson’s correlation (r) is used to estimate the level of correlation among two continuous and normally-distributed variables and ranges from -1 to 1. Perhaps too obvious for comment, but values &lt; 0 indicated a negative relationship, values &gt; 0 indicate a positive relationship with 0 indicating no relationship. There is no test of significance per se for the Pearson. However, there are some general guidelines. Generally speaking, r &lt; |0.3| is considered weak, moderate values are |0.3| &lt; r &lt; |0.7|, and an r &gt; |0.7| is considered high correlation. The “|” around the numbers indicate they can take on a negative or positive value. 7.1.2 Non-parametric correlations Often times data are not normally distributed or continuous. Luckily, a series of other statistics have been developed to measure the relationships among variable with different measurement scales. After Pearson’s correlation coefficient, the next most common approach in ecology and environment is likely the Spearman’s rank correlation. Spearman’s correlates two variables measured on the ordinal scale. The raw data may have actually been measured on an ordinal scale or if data are continuous, but not normally distributed, the researcher may decide to convert the variable to the ordinal scale and assess correlation using a Spearman’s rank correlation. This type of transformation from a non-normal continuous variable to a rank-ordered variable is a common approach in non-parametric statistics (e.g., Wilcoxon, Mann-Whitney U-test) and we encounter it again when dealing with GLMs. An alternative to Spearman’s that you may encounter is Kendall’s tau, which is an alternative test of association between oridinal data. My experience suggests it is less common in the ecology and environment literature. Categorical data provide a different challenge and associations (i.e., correlations) are commonly assessed using the Pearson Chi-squared test for independence. With this type of data we are testing an explicit hypothesis. The null hypothesis (\\(H_0\\)): no association between the two variables, is compared against the alternative hypothesis (\\(H_A\\)): there is an association between the two variables. The Chi-squared test results in a significance test which can reject the null hypothesis. Cramer’s V can be used as a follow-up to the Chi-squared test. Cramer’s V does not reject or fail to reject a hypothesis and is more similar to the Pearson’s correlation coefficient in its interpretation producing a value between 0 (no association) and 1 (perfect association). Guidelines suggest that a Cramer’s V of &lt; 0.25 indicates a week association and &gt; 0.75 is a moderate association. All the above approaches assume that individual observations are drawn randomly from the population. 7.1.3 Non-parametic correlations in a GLM context We have explored how to address pairwise correlations and why this is an important pre-screening exploration before we start fitting models. Basically, in a GLM context, we should not have highly correlated predictor variables in the same model. We cover why this is true throughout the lectures. The same is true with categorical variables in a GLM context. If categorical variables are highly correlated, then we need to be cautious about their inclusion as predictor variables in the same model. The process for assessing correlations among categorical predictors is slightly more involved that with continuous or ordinal data, but should be done prior to model fitting, and includes 3 steps. These steps are outlined in detail in the code below and involve: 1. creation of a contingency table, 2. Chi-squared test of association, 3. Calculation of Cramer’s V. These three steps should be done for each possible pairwise correlation of interest. Load the required packages. Remember, you must make sure they are installed. The car package is used for the VIF estimation (more on this below) and teh vcd package provides the assocstats function to calculate Cramer’s V. packages.needed &lt;- c(&quot;car&quot;, &quot;vcd&quot;) lapply(packages.needed, FUN = require, character.only = TRUE) Next we load data that contains three categorical predictors with a continuous response variable. The downloaded from the UW LEARN site. df1 = read.csv(&quot;DATA/cat_correlation_1.csv&quot;, header = TRUE) summary (df1) ## habitat disturbance fertilizer species_diversity ## Length:300 Length:300 Length:300 Min. : 0.3983 ## Class :character Class :character Class :character 1st Qu.: 7.1079 ## Mode :character Mode :character Mode :character Median : 9.6998 ## Mean : 9.5893 ## 3rd Qu.:11.9146 ## Max. :18.6236 This data set contains data on species diversity levels measured across 5 different habitat types, 2 levels of disturbance, and 3 different types of fertilizer treatments. For this example, we are assuming we did not have control over study design. For example, these data could have been provided by an agency or organization. In other words, the distribution of the different categories of fertilizer and disturbance do not necessarily represent a balanced design across habitats. Therefore, we need to look for potential correlations among all possible pairwise combinations of the predictor variables. The questions we are asking are: Is there correlation between habitat type and disturbance? Is there correlation between habitat type and fertilizer? Is there correlation between disturbance and fertilizer? Before we can run a Chi-squared test for each possible pairwise comparison, we need to create a contingency table. The next step involves, running the Chi-squared test on the contingency table. We then follow this with the calculation of Cramer’s V. ## Habitat vs Disturbance cat(&quot;\\n--- Habitat vs Disturbance ---\\n&quot;) # contingency table tab_hd &lt;- table(df1$habitat, df1$disturbance) # Chi-squared test chi_hd &lt;- chisq.test(tab_hd) print(chi_hd) # Cramer&#39;s V assoc_hd &lt;- assocstats(tab_hd) cat(&quot;Cramer&#39;s V:&quot;, assoc_hd$cramer, &quot;\\n&quot;) ## Habitat vs Fertilizer: cat(&quot;\\n--- Habitat vs Fertilizer ---\\n&quot;) # contingency table tab_hf &lt;- table(df1$habitat, df1$fertilizer) # Chi-squared test chi_hf &lt;- chisq.test(tab_hf) print(chi_hf) # Cramer&#39;s V assoc_hf &lt;- assocstats(tab_hf) cat(&quot;Cramer&#39;s V:&quot;, assoc_hf$cramer, &quot;\\n&quot;) ## Disturbance vs Fertilizer: cat(&quot;\\n--- Disturbance vs Fertilizer ---\\n&quot;) # contingency table tab_df &lt;- table(df1$disturbance, df1$fertilizer) # Chi-squared test chi_df &lt;- chisq.test(tab_df) print(chi_df) # Cramer&#39;s V assoc_df &lt;- assocstats(tab_df) cat(&quot;Cramer&#39;s V:&quot;, assoc_df$cramer, &quot;\\n&quot;) ## ## --- Habitat vs Disturbance --- ## ## Pearson&#39;s Chi-squared test ## ## data: tab_hd ## X-squared = 3.069, df = 4, p-value = 0.5463 ## ## Cramer&#39;s V: 0.1011441 ## ## --- Habitat vs Fertilizer --- ## ## Pearson&#39;s Chi-squared test ## ## data: tab_hf ## X-squared = 2.2989, df = 8, p-value = 0.9705 ## ## Cramer&#39;s V: 0.06189881 ## ## --- Disturbance vs Fertilizer --- ## ## Pearson&#39;s Chi-squared test ## ## data: tab_df ## X-squared = 2.2199, df = 2, p-value = 0.3296 ## ## Cramer&#39;s V: 0.08602138 The pre-screening of correlations among variables is complete and there does not appear to be any substantial correlations among the covariates. However, it is good practice to assess potential correlations after you have fit the model(s) using the Variance Inflation Factor (VIF). This value is computed for each predictor in your regression models and tells you how much of the variance (or uncertainty) of each variable’s coefficient estimate is “inflated” due to correlation with other predictors. A high VIF can lead to less precise estimates and unstable coefficients. This means that small changes in the data could lead to large changes in the estimated coefficients. A *high( VIF could also indicate that it is difficult to distinguish the individual effect of a predictor on the response variable due to shared information between predictors. This can be addressed by combining similar predictors, removing one of the correlated predictors (discussed in lecture), or reconsidering the model specification. The thresholds for VIF are guidelines and not absolute cutoffs. Generally, the following guidelines are used: Low VIF (VIF \\(\\approx\\) 1): Predictor is independent of others. Moderate VIF (1-5): Some collinearity exists, but generally acceptable. High VIF (&gt;5): Strong collinearity exists, which may inflate standard errors, make coefficeint estimates unstable, and the model should be re-evaluated. # Fit a linear model and assess multicollinearity: model_1 &lt;- lm(species_diversity ~ habitat + disturbance + fertilizer, data = df1) ## ## --- Summary model_1 --- ## ## Call: ## lm(formula = species_diversity ~ habitat + disturbance + fertilizer, ## data = df1) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.49246 -0.69073 0.02853 0.66337 2.71803 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 13.3690 0.1677 79.730 &lt; 2e-16 *** ## habitatHabitat2 0.7772 0.1812 4.289 2.44e-05 *** ## habitatHabitat3 1.7964 0.1907 9.421 &lt; 2e-16 *** ## habitatHabitat4 2.8294 0.1960 14.437 &lt; 2e-16 *** ## habitatHabitat5 3.8465 0.1790 21.489 &lt; 2e-16 *** ## disturbanceNotDisturbed -4.2486 0.1209 -35.128 &lt; 2e-16 *** ## fertilizerFert2 -2.9551 0.1527 -19.348 &lt; 2e-16 *** ## fertilizerFert3 -6.2296 0.1455 -42.819 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.035 on 292 degrees of freedom ## Multiple R-squared: 0.9219, Adjusted R-squared: 0.92 ## F-statistic: 492.1 on 7 and 292 DF, p-value: &lt; 2.2e-16 ## ## --- VIF model_1 --- ## GVIF Df GVIF^(1/(2*Df)) ## habitat 1.017629 4 1.002187 ## disturbance 1.017372 1 1.008649 ## fertilizer 1.014727 2 1.003662 The results of the above assessment indicate there are no concerns regarding high correlation among the potential predictor variables. You can follow the same example above with a different data set to see how the results differ. These data are also available on the LEARN site. df2 = read.csv(&quot;DATA/cat_correlation_2.csv&quot;, header = TRUE) summary (df1) ## habitat disturbance fertilizer species_diversity ## Length:300 Length:300 Length:300 Min. : 0.3983 ## Class :character Class :character Class :character 1st Qu.: 7.1079 ## Mode :character Mode :character Mode :character Median : 9.6998 ## Mean : 9.5893 ## 3rd Qu.:11.9146 ## Max. :18.6236 ## Warning in chisq.test(tab_hf): Chi-squared approximation may be incorrect ## ## --- Habitat vs Disturbance --- ## ## Pearson&#39;s Chi-squared test ## ## data: tab_hd ## X-squared = 2.4936, df = 4, p-value = 0.6458 ## ## Cramer&#39;s V: 0.091171 ## ## --- Habitat vs Fertilizer --- ## ## Pearson&#39;s Chi-squared test ## ## data: tab_hf ## X-squared = 11.077, df = 8, p-value = 0.1974 ## ## Cramer&#39;s V: 0.1358721 ## ## --- Disturbance vs Fertilizer --- ## ## Pearson&#39;s Chi-squared test ## ## data: tab_df ## X-squared = 152.96, df = 2, p-value &lt; 2.2e-16 ## ## Cramer&#39;s V: 0.714038 These results indicate a high level of correlation between our disturbance and fertilizer variables. Below we can see the consequences of including these two variables in the same model for our estimated VIF values. # Fit a linear model and assess multicollinearity: model_2 &lt;- lm(species_diversity ~ habitat + disturbance + fertilizer, data = df2) ## ## --- Summary model_2 --- ## ## Call: ## lm(formula = species_diversity ~ habitat + disturbance + fertilizer, ## data = df2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.33886 -0.72173 0.05189 0.58885 2.51848 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 12.7497 0.1362 93.58 &lt; 2e-16 *** ## habitatHabitat2 1.0818 0.1751 6.18 2.15e-09 *** ## habitatHabitat3 2.1290 0.1620 13.14 &lt; 2e-16 *** ## habitatHabitat4 3.1152 0.1813 17.18 &lt; 2e-16 *** ## habitatHabitat5 4.0686 0.1690 24.07 &lt; 2e-16 *** ## disturbanceNotDisturbed -3.8421 0.1570 -24.47 &lt; 2e-16 *** ## fertilizerFert2 -3.0478 0.2082 -14.64 &lt; 2e-16 *** ## fertilizerFert3 -5.9718 0.1645 -36.30 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.9459 on 292 degrees of freedom ## Multiple R-squared: 0.9618, Adjusted R-squared: 0.9609 ## F-statistic: 1050 on 7 and 292 DF, p-value: &lt; 2.2e-16 ## ## --- VIF model_2 --- ## GVIF Df GVIF^(1/(2*Df)) ## habitat 1.048866 4 1.005982 ## disturbance 2.061176 1 1.435680 ## fertilizer 2.122102 2 1.206956 The above results suggest a moderate VIF level. At this point, it is likely best to proceed with additional model evaluation steps. The following are steps that are advisable and covered in more detail in later chapters, but listed here for reference: Based on your results—where the VIF for disturbance and fertilizer is a little over 2 (which indicates moderate but not alarming collinearity)—you can move forward with additional model evaluation steps. Here are several recommended next steps: Residual Diagnostics: Residual Plots: Check residual-versus-fitted values to ensure that there are no obvious patterns (which might indicate nonlinearity or heteroscedasticity). Normality of Residuals: For models where normality is assumed (like linear regression in the above example), a Q–Q plot can help assess if residuals are approximately normally distributed. Influence and Leverage: Calculate diagnostic measures (e.g., Cook’s distance) to see if any individual observations have an outsized influence on your model estimates. Goodness-of-Fit and Model Comparison: Information Criteria: Use metrics such as AIC (Akaike Information Criterion) to compare alternative model specifications (e.g., models with or without interaction terms, or with different sets of predictors). Cross-Validation: If prediction is a goal, consider using cross-validation or a hold-out sample to assess the predictive performance of your model. Model Specification: Interactions: Given the ecological context, it may be worthwhile to explore whether interactions (for example, between disturbance and fertilizer) add important explanatory power to your model. Substantive Interpretation and Sensitivity Analysis: Coefficient Interpretations: Check that the estimated effects of your predictors make sense from an ecological perspective. Sensitivity Checks: If you’re concerned about even moderate collinearity, you might explore models where you combine or drop one of the correlated variables to see if the substantive conclusions change. 7.2 Regression The simplest linear models we can develop are linear regression models. These models are similar to the concept of correlation introduced in the previous section in that we are only examining two variables. However, linear regression differs from correlation in several important ways. Conceptually, the biggest difference, is that in a linear regression you are proposing a directional relationship. When we looked at correlations, we were simply interested in whether there was a relationship between two variables, but we did not propose a cause and effect relationship. In other words, in correlation, it does not matter what variable is on the \\(y\\) axis and what variable was on the \\(x\\) axis. The variables are interchangeable between axes. This is not true of a linear regression. For a linear regression, we must specify which of the variables we are trying to predict (i.e., which variable is the dependent variable. This variable is the \\(y\\) variable. The predictor (i.e., independent variable) is the \\(x\\) variable. Our selection of dependent \\(y\\) and independent \\(x\\) variables is informed by our question and the hypotheses that we want to test. Essentially, the \\(y\\) is what you want to predict - your response variable of interest - and your \\(x\\) is something that influences that response. We will go through many examples throughout the book. These models form the basis for all subsequent and more sophisticated modelling that we will explore in this book. Essentially, a simple linear regression models a linear (i.e., straight line) relationship between a response variable \\(y\\) with a normal distribution and a single, numerical, explanatory variable. We introduced the linear model in the past chapter. A simple linear regression is even… well… simpler and can be represented by the following equation. \\[y_i = \\beta_0 + \\beta_1x_1 + \\epsilon_i\\] Another common way of representing this equation involves presenting more detail about the shape of the response variable. In this case, we specify the response variable has a normal distribution (\\(Y\\) ~ Normal(\\(\\mu_Y, \\sigma^2_Y\\))) and therefore our model is written as: \\[\\mu_Y = \\beta_0 + \\beta_1x_1 + \\epsilon_i\\] The \\(\\beta_0\\) and \\(\\beta_1x_1\\) have the same interpretation. As a reminder, \\(\\beta_0\\) is the intercept (i.e., where the line crosses the \\(y\\) axis). Or, in other words, \\(\\beta_0\\) is the predicted value of \\(\\mu_y\\) when \\(x\\) = 0. The slope of the straight line is \\(\\beta_1\\). I once had a highly respected and intelligent professor tell me that, in ecology, “it is all about the Betas”. This slope can be presented as the rate of change in \\(\\mu_Y\\) per unit change in the explanatory variable \\(x_1\\). Throughout the book, I have tried to use ‘real’ ecological data collected by me and my colleagues. I think this is important because the data are messy and frequently do not behave well. These data can have challenging distributions that can make fitting models to the data difficult. Sometimes wrangling ‘real’ world ecological data and fitting models to those data is as frustrating and challenging as stuffing a tired and angry toddler into a snow suit… in a hot room… while sleep deprived… with your mother-in-law explaining how you are going to be late while she muses that she never had such problems with her kids. But, working with those data will help you with your own data. However, while digging through all the many datasets I have compiled across my career, it turns out I have never collected data that could be modeled using a simple linear regression. Lucky me. So the following data and examples are from the excellent textbook by Pablo Inchausti, Statistical Modeling with R, which is currently available through the UW library for this course. The author’s website with data, code, and extra material can be found here. The data we will work with look at plant tolerance and cadmium levels. Cadmium (Cd) is a metal that has toxic effects on plant and human health. The researchers grew grass in soils with different concentrations of Cd to determine if the grass was a bioaccumulator of the metal to assess its usefulness in bioremediation. More details can be found in the textbook. First, we will make sure the packages required are loaded. Remember, you must make sure they are installed. packages.needed &lt;- c(&quot;ggplot2&quot;, &quot;broom&quot;, &quot;qqplotr&quot;, &quot;cowplot&quot;, &quot;ggeffects&quot;) lapply(packages.needed, FUN = require, character.only = TRUE) Next we load the data provided by Inchausti. The data can be downloaded from the author’s website (referenced above) or the UW LEARN site. df = read.csv(&quot;DATA/Ch 04 Cadmium.csv&quot;, header = TRUE) summary (df) ## soil shoot root ## Min. : 60 Min. : 16.20 Min. : 104.6 ## 1st Qu.:120 1st Qu.: 52.65 1st Qu.: 245.1 ## Median :180 Median :123.70 Median : 465.0 ## Mean :180 Mean :117.02 Mean : 502.8 ## 3rd Qu.:240 3rd Qu.:171.18 3rd Qu.: 664.6 ## Max. :300 Max. :217.70 Max. :1067.1 The soil variable represents the level of Cd in the soil and the shoot variable represents the amount of Cd in the shoots. The model we want to fit is: \\[shoot = \\beta_0 + \\beta_1soil + \\epsilon_1\\] The \\(\\epsilon\\) represents the residuals and there are explicit assumptions about its distribution also. In this case we assume the residuals will follow a normal distribution with a mean = 0. Fitting a simple linear regression in R uses the lm function which is part of the stats package. You do not need to load this package because it is automatically loaded by default at the start of every R session. We fit the linear model to our data using the following: m1 &lt;- lm(shoot ~ soil, data = df) The code above fits the model we specified in the equation above. The shoot response variable and soil predictor covariate are present in the code. However, we do not need to specify any of the model-estimated components such as the intercept \\(\\beta_0\\) the slope of the relationship \\(\\beta_1\\) or the error term \\(\\epsilon_1\\) because these are unknown to us and are produced by the model estimating function lm. The tilde sign ~ in R fills the place of the = in the equation and separates the response and predictor variables. We also must specify the data frame which contains the variables with the data = df code. We store the results by assigning the model to an object (m1 in the example above) which creates a list containing model results. The most relevant model results are provided using the summary command. summary(m1) ## ## Call: ## lm(formula = shoot ~ soil, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -25.970 -11.220 1.730 7.655 28.680 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -19.03000 8.35547 -2.278 0.0352 * ## soil 0.75583 0.04199 18.001 5.88e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 15.93 on 18 degrees of freedom ## Multiple R-squared: 0.9474, Adjusted R-squared: 0.9445 ## F-statistic: 324 on 1 and 18 DF, p-value: 5.882e-13 7.2.1 Interpreting Output The most important model estimates are presented under the Coefficients heading (remember “It’s all about the Betas”). The summary output presents estimates of the intercept (\\(\\beta_0\\)), the slope (\\(\\beta_1soil\\)), and the standard errors associated with each estimate (i.e., the variation around the estimate). The Coefficients section also presents the t value and the p-value (Pr(&gt;|t|)). Recall from lecture, that within this frequentist paradigm all of these parameters are estimated using a maximum likelihood approach. The p-value is calculated based on the t-distribution which is a type of normal distribution, centered on zero, in which the variance is estimated based on the degrees of freedom. The degrees of freedom are related to your sample size. Increasing the sample size decreases the variance, essentially narrowing your normal distribution. The p-value presented in the output represents the probability of obtaining a t-value equal to or more extreme than the one obtained if the null hypothesis is true (i.e. \\(\\beta_1\\) = 0). Therefore, the p-value essentially measures the lack of congruence between the data and the null hypothesis. In a frequentist context, the p-value essentially answers the question of how frequently we would observe the data if we ran this experiment many times. Data that deviate from the null hypothesis, based on model assumptions, have lower p-values. We will work through a simulation exercise in class that will hopefully be illuminative. In order to determine whether the results are actually important we must interpret the magnitude of the estimated slope and its error in the context of the ecology and research questions that motivated the data collection. In the example above, that means we need to decide if the absorption of 75.5% of the soil Cd by plants is important. The estimated intercept \\(\\beta_0\\) of -19.03 is largely meaningless in the context of this model because it estimates the average shoot concentration when there is no Cd in the soil (i.e. Cd = 0). Later we will discuss the possibility of standardizing your predictor variables and how that affects our interpretation of the intercept in linear models. The bottom of the output presents several measures of the model performance. Each model can be used to generate predicted values (i.e., the value of the response variable if the model is true). The Residual standar error essentially represents difference between observed and predicted values (i.e, the estimated variance of the residuals or unexplained variance in the model). The Multiple R-squared and the Adjusted R-squared values are the proportion of variation in the response variable that is explained by the model. You can find plenty of mathematical descriptions of the difference between these two metrics online, if you are interested. The main difference is that Multiple R-squared will stay the same or increase as you add new predictors (i.e., covariates) to the model. This is true even if the new predictors are uninformative. Whereas Adjusted R-squared only increases if the new predictors improve the models predictive power and will decrease if the predictors are irrelevant to the models predictive performance. These values are both a measure of the goodness of fit of the model to the data. Higher values represent a better fit to the data, but should largely only be considered in a comparative context (i.e., in relation to other models fitted to the same data). The Residuals: section at the top of the model output is largely irrelevant to model interpretation. Statistics is so relevant to the real world because it allows us to estimate the inherent uncertainty underlying any complex problem. The Std. Error component give us some indication of the variability around the estimated parameter, but it is typically considered a fairly narrow or overly optimistic estimate of our confidence in the estimate. Therefore, it is common to estimate the confidence interval surrounding the parameter estimate. The interpretation of a confidence interval in a frequentist context is different than in a Bayesian context. In a frequentist context, the confidence interval is a range of equally plausible values of the parameter that we could obtain if we repeated this study many times with the same sample size and the same population. As an aside, in a Bayesian context we would estimate a 95% credible interval which would be accurately interpreted as: there is a 95% chance the true value is within the range presented. This is different. To obtain the confidence interval for the model m1 we use the confint( ) function. confint(m1) ## 2.5 % 97.5 % ## (Intercept) -36.5841840 -1.4758160 ## soil 0.6676202 0.8440464 So, what is the best way to interpret confidence intervals in the frequentist context? Consider it as a thought experiment. If we ran this study over and over again in the same population with the same sample size, we would end up with a distribution of parameter estimates with a lower 2.5% bound of 0.668 and an upper 97.5% bound of 0.844. Hopefully the example in class helps to further clarify this concept. 7.3 Model Validation It is not enough to fit a model and simply present the parameter estimates. We also need to determine if it is a ‘good’ model. In other words, does the model fit the data well? The residuals and their distribution are the main focus of model validation. Essentially, the smaller the residuals (i.e., the difference between the observed and predicted values) the better the model fits the data. In addition to the basics of minimizing \\(Y_{obs} - Y_{pred}\\) we also want simple and random patterns in the distribution of our residuals. Any trends in the residuals can be an indication of poor model fit. With a general linear model, the default model validation summary produces four graphs. You can produce these in base R with the plot(model_name) function. However, for greater flexibility and insight we will produce validation figures using ggplot. This approach is also used throughout most of the examples in Inchausti’s textbook. The first graph plots the Residuals vs. the Fitted values. The residuals are estimated for each of the observed values and are presented in the y-axis. Remember the residuals are estimated as \\(Y_{obs} - Y_{pred}\\) and can therefore take on positive and negative values that should be distributed randomly around 0. The fitted values represent the model predicted values,encompass the range of your observed data, and are plotted on the x-axis. If the model fits the data well, we should see an even distribution of points scattered on both sides of the 0 value. There should be no visible pattern to the distributed values (i.e., cone shaped). This implies a homogeneous distribution of the residuals, which is an informal assessment of homoscedacity (i.e., homogeneity of variance). A parallel plot to the Residuals vs. Fitted values, replaces the x-axis fitted values with the actual observed values and should have a similar pattern. The third common plot presents the sample quantiles on the y-axis and the theoretical quantiles on the x-axis. Since this plot presents the two quantiles and is used to assess the ‘normality’ of the data, it is often refereed to as the “Normal Q-Q plot”. Quantiles are points in your data below which a certain proportion of your data fall. In a normal distribution with a mean of 0, the 0.5 quantile (i.e., 50th percentile) is 0. The quantiles presented are basically your data sorted in ascending order with each data point labelled as the point below which a certain proportion of the data fall. Therefore, if the model predicted (Theoretical quantiles) match the observed (Sample quantiles) perfectly, they will lie along a perfect diagonal. Thus,if the residuals are normally distributed, they should have a relatively tight scatter of points along the line of perfect fit. It is very common for the points near the tail ends of the distribution (upper and lower) to deviate more from the theoretical perfect fit than the points closer to the center for the distribution. This makes sense because there are more data to inform model fit in the central regions of the distribution than near the tails. The final common model validation plot presents Cook’s distance. This is essentially a sensitivity analysis that quantifies the impact of each data point on the parameter estimates. Data points with a “large” Cook’s distance may have an unduly large influence on the parameter estimates. There is no hard-and-fast rule to decide when a Cook’s distance is “too” large. Like much of model validation, it is somewhat subjective and relies on our visual interpretation of the validation plots. If you are concerned about the influence of a particular observation, you can remove that observation, re-run the model and look at the changes in the model parameter estimates. The Cook’s distance plot presents the observations in your data set in order along the x-axis so it is easy to identify potentially large observations. The y-axis presents the Cook’s distance. If you are interested, I will leave you to look up the actual calculation of Cook’s distance on your own. It is not necessary to understand the underlying mathematics in detail. It is enough to know what it represents and how it can inform your modelling choices and interpretation. Producing ggplot-type figures requires use of the package broom. First, we create a tibble. tidy(m1, conf.int=TRUE) ## # A tibble: 2 × 7 ## term estimate std.error statistic p.value conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) -19.0 8.36 -2.28 3.52e- 2 -36.6 -1.48 ## 2 soil 0.756 0.0420 18.0 5.88e-13 0.668 0.844 The glance function gathers the model fit data into a more user-friendly format. glance(m1) ## # A tibble: 1 × 12 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.947 0.944 15.9 324. 5.88e-13 1 -82.7 171. 174. ## # ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt; Then we create a data frame containing all the information required to produce the four plots. Most importantly, this data frame includes the empirical data, the model fitted values, Cook’s distance, residuals. You can follow the ggplot code below to see what variables are used to create each plot. The code provided comes directly from Inchausti Ch.4 with some slight modifications. The augment function accepts a model object and adds information about each observation in the dataset. These are the values we will plot. augment(m1) ## # A tibble: 20 × 8 ## shoot soil .fitted .resid .hat .sigma .cooksd .std.resid ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 23.2 60 26.3 -3.12 0.150 16.4 0.00398 -0.212 ## 2 16.2 60 26.3 -10.1 0.15 16.2 0.0419 -0.689 ## 3 52.7 60 26.3 26.4 0.15 14.9 0.285 1.80 ## 4 29.1 60 26.3 2.78 0.15 16.4 0.00316 0.189 ## 5 52.5 120 71.7 -19.2 0.075 15.7 0.0634 -1.25 ## 6 45.7 120 71.7 -26.0 0.075 15.0 0.116 -1.69 ## 7 52.9 120 71.7 -18.8 0.075 15.7 0.0608 -1.22 ... Notice the table includes one row for each of the observations (only display 7 above). The next step is to store the results of augment(m1) in order to create the plots. res.m1 &lt;- augment(m1) # ggplots of the residual analysis of of Frequentist simple regression m1.res=ggplot(data=res.m1, aes(x=.fitted, y=.resid)) + geom_point(size=1) + theme_bw() + geom_hline(yintercept = 0) + labs(x=&quot;Fitted values&quot;, y=&quot;Standard residuals&quot;) + theme(axis.title=element_text(size=12), axis.text = element_text(size=10)) m1.res.vs.expl=ggplot(data=res.m1, aes(x=soil, y=.resid)) + geom_point(size=1) + theme_bw() + geom_hline(yintercept = 0) + labs(x=&quot;Cd in soil&quot;, y=&quot;stnd residuals&quot;) + theme(axis.title.x=element_text(size=12), axis.title.y = element_blank(), axis.text = element_text(size=10)) m1.Cook=ggplot(data=res.m1, aes(x=1:nrow(res.m1),y=.cooksd)) + geom_linerange(aes(ymin=0, ymax=.cooksd)) + theme_bw() + labs(x=&quot;Data point&quot;, y=&quot;Cook distance&quot;)+ theme(axis.title=element_text(size=12), axis.text = element_text(size=10)) m1.qq=ggplot(res.m1, mapping=aes(sample = .std.resid)) + stat_qq_point() + theme_bw() + stat_qq_line() + stat_qq_band(alpha=0.3) + labs(x = &quot;Theoretical quantiles&quot;, y = &quot;Sample quantiles&quot;) + theme(axis.title=element_text(size=12), axis.text = element_text(size=10)) plot_grid(m1.res, m1.res.vs.expl, m1.qq, m1.Cook, ncol=2,labels = LETTERS[1:4], align=&quot;hv&quot;,label_x=0.85, label_y=0.95) # Fig 4.5 in Inchausti "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
